import re
import os
import json
import time
import pickle
from tqdm import tqdm
from openai import OpenAI
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from time_filter import filter_time
from prompt_templates.fs_example import examples


def load_jsonl_file(file_path):
    data = []
    with open(file_path, 'r') as infile:
        for line in infile:
            d = json.loads(line)
            data.append(d)
    return data

def build_prompt(prompt_type, issue_title, issue_description, issue_component, source):
    with open(prompt_templates[prompt_type], 'r', encoding='utf-8') as f:
        template = f.read().strip()
    index_key = f"{issue_title}\n{issue_description}"
    
    if prompt_type == 'few_shot':
        example_title_1 = examples[source][0]['title']
        example_description_1 = examples[source][0]['description']
        
        example_title_2 = examples[source][1]['title']
        example_description_2 = examples[source][1]['description']
        
    if prompt_type == 'RAG':
        # RAG logic to fill in examples
        example_title_1 = rag_example_dict[source][index_key]['tp_title']
        example_description_1 = rag_example_dict[source][index_key]['tp_description']
        
        example_title_2 = rag_example_dict[source][index_key]['fp_title']
        example_description_2 = rag_example_dict[source][index_key]['fp_description']
    
    if prompt_type in ['few_shot', 'RAG']:
        prompt = template.format(
            ISSUE_TITLE=issue_title, 
            ISSUE_DESCRIPTION=issue_description,
            ISSUE_COMPONENT=issue_component,
            EXAMPLE_TITLE_1=example_title_1,
            EXAMPLE_DESCRIPTION_1=example_description_1,
            EXAMPLE_TITLE_2=example_title_2,
            EXAMPLE_DESCRIPTION_2=example_description_2
        )
    else:
        prompt = template.format(ISSUE_TITLE=issue_title, ISSUE_DESCRIPTION=issue_description, ISSUE_COMPONENT=issue_component)
    return prompt


def extract_model_prediction(model_output: str) -> str:
    # Try to load as JSON directly
    try:
        data = json.loads(model_output)
        if "label" in data:
            return data["label"]
    except json.JSONDecodeError:
        pass
    
    try:
        # Try to extract JSON substring from ```json ... ``` block
        match = re.search(r'```json(.*?)```', model_output, re.DOTALL)
        if match:
            json_str = match.group(1).strip()
            data = json.loads(json_str)
            if "label" in data:
                return data["label"]
    except json.JSONDecodeError:
        pass
    
    # Fallback: regex search for "label": "..."
    match = re.search(r'"label"\s*:\s*"([^"]+)"', model_output)
    if match:
        return match.group(1)
    
    return None


def call_model(system_prompt, prompt, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model=MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                    ],
                temperature=0.,
                max_tokens=300,
                timeout=30
            )
            content = response.choices[0].message.content.strip()
            return content
        except Exception as e:
            print(f"Attempt {attempt+1}/{max_retries} failed: {str(e)}")
            time.sleep(5 ** attempt)
    return ''

def preprocess_email(single_data, data_type):
    if data_type == 'syz':
        title = single_data['title']['text']
        description = single_data['mails'][-1]['mail_list'][0]['content']
        component = single_data['subsystems'][0]['name']
    elif data_type == 'bugzilla':
        title = single_data['title']
        # description = single_data['comments'][0] if single_data['comments'][0] != "" else single_data['comments'][1]
        description = single_data['comments'][0]
        component = single_data['product']
    else:
        title, description, component = '', '', ''
    
    # Basic preprocessing: remove excessive whitespace
    title = ' '.join(title.split())
    
    return title, description, component


def process_dataset(data, source, prompt_type, system_prompt):
    """Process a dataset and return true labels and predicted labels."""
    true_labels, preds, justification = [], [], []
    
    for item in tqdm(data):
        title, description, component = preprocess_email(item, source)
        
        description = description.split('This report is generated by a bot.')[0] if source == 'syz' else description
        if not title or not description:
            continue

        prompt = build_prompt(prompt_type, title, description,component, source)
        pred_text = call_model(system_prompt, prompt).lower()
        pred_label = extract_model_prediction(pred_text)

        if "genuine_bug" in pred_label:
            pred = 1
        elif "false_positive" in pred_label:
            pred = 0

        label = int(item.get("label_type") == "fp")

        print(f"Label: {label}, Pred: {pred}")
        true_labels.append(label)
        preds.append(pred)
        justification.append(title+pred_text)
    

    return true_labels, preds, justification


def compute_metrics(y_true, y_pred):
    return {
        "accuracy": accuracy_score(y_true, y_pred),
        "precision": precision_score(y_true, y_pred),
        "recall": recall_score(y_true, y_pred),
        "f1_score": f1_score(y_true, y_pred)
    }
    
def main(prompt_type, source):

    # syz_recent_data, bugzilla_recent_data = filter_time(syz_data, bugzilla_data, "2024-07-01")
    syz_recent_data, bugzilla_recent_data = syz_data, bugzilla_data
    #temp only fp
    # bugzilla_recent_data = [item for item in bugzilla_recent_data if item['label_type'] in ['fp']]

    with open('data/bugzilla_recent_data.json', 'w') as f:
        json.dump(bugzilla_recent_data, f, indent=2)
    print('syz data size:', len(syz_recent_data))
    print('syz fp number:', sum(1 for item in syz_recent_data if item.get("label_type") == "fp"))
    print('syz tp number:', sum(1 for item in syz_recent_data if item.get("label_type") == "tp"))
    print('bugzilla data size:', len(bugzilla_recent_data))
    print('bugzilla fp number:', sum(1 for item in bugzilla_recent_data if item.get("label_type") == "fp"))
    print('bugzilla tp number:', sum(1 for item in bugzilla_recent_data if item.get("label_type") == "tp"))
    
    todo_data = syz_recent_data if source == 'syz' else bugzilla_recent_data
    
    true_label, pred, justification = process_dataset(todo_data, source, prompt_type, system_prompt)
    res = compute_metrics(true_label, pred)
    
    
    print(f"\n{source.capitalize()} Data Metric :")
    print(f"Accuracy:  {res['accuracy']:.4f}")
    print(f"Precision: {res['precision']:.4f}")
    print(f"Recall:    {res['recall']:.4f}")
    print(f"F1-score:  {res['f1_score']:.4f}")
    
    
    all_res = {
        f'{source}_true': true_label,
        f'{source}_pred': pred,
        f'{source}_justification': justification
    }
    # get time stamp
    time_stamp = time.strftime("%Y%m%d-%H%M%S", time.localtime())
    res_dir = f'./results/{prompt_type}/{source}/{time_stamp}'
    os.makedirs(res_dir, exist_ok=True)
    
    with open(f'{res_dir}/predicted_res.json', 'w') as f:
        json.dump(all_res, f, indent=2)
        
    with open(f'{res_dir}/metrics_summary.txt', 'w') as f:
        f.write(f"{source.capitalize()} Data Metrics :\n")
        f.write(f"Accuracy:  {res['accuracy']:.4f}\n")
        f.write(f"Precision: {res['precision']:.4f}\n")
        f.write(f"Recall:    {res['recall']:.4f}\n")
        f.write(f"F1-score:  {res['f1_score']:.4f}\n\n")
    with open(prompt_templates[prompt_type], 'r', encoding='utf-8') as pf:
            prompt_content = pf.read().strip()

    with open(f'{res_dir}/prompt_template_used.txt', 'w') as f:
        f.write(prompt_content)




if __name__ == '__main__':
    client = OpenAI(
        api_key="",
        base_url=""
    )
    MODEL = "deepseek-ai/DeepSeek-V3"  

    prompt_templates = {
        'zero_shot': 'prompt_templates/basic_zero_shot',
        'enhanced_zero_shot': 'prompt_templates/enhanced_zero_shot',
        'cot': 'prompt_templates/chain_of_thought',
        'few_shot': 'prompt_templates/few_shot',
        'RAG': 'prompt_templates/RAG'
    }
    
    with open('prompt_templates/system_prompt', 'r', encoding='utf-8') as f:
        system_prompt = f.read().strip()

    bugzilla_data_file = 'data/bugzilla_data.jsonl'
    syz_data_file = 'data/syzkaller_data.jsonl'
    
    syz_data = load_jsonl_file(syz_data_file)
    bugzilla_data = load_jsonl_file(bugzilla_data_file)

    prompt_type = 'cot'  # Options: 'zero_shot', 'enhanced_zero_shot', 'cot', 'few_shot', 'RAG'

    if prompt_type == 'RAG':
        syz_rag_example_dict = pickle.load(open('./data/rag_embeddings_syz.pickle', 'rb'))
        bugzilla_rag_example_dict = pickle.load(open('./data/rag_embeddings_bugzilla.pickle', 'rb'))
        # print(bugzilla_rag_example_dict)

        rag_example_dict = {
            'syz': syz_rag_example_dict,
            'bugzilla': bugzilla_rag_example_dict
        }
    # syz or bugzilla
    source = 'bugzilla' 
    main(prompt_type, source)
